{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrencemacbook/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_file = open(\"training/training_vects_y.pkl\", \"r\")\n",
    "y = pickle.load(y_file)\n",
    "y_col = zip(*y)\n",
    "y_pos = y_col[0]\n",
    "y_neg = y_col[1]\n",
    "y_neu = y_col[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import zipfile\n",
    "archive = zipfile.ZipFile('training.zip', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_file = archive.open(\"training/raw_training_vects_x.pkl\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 20, 17, 16, 19, 514580)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('~/Downloads/training_csv/raw_training_vects_x.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_list = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/lawrencemacbook/Downloads/training_csv/raw_training_vects_x.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X = list(reader)\n",
    "X = np.array(X)\n",
    "n_feature = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2000, input_dim=n_feature, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 11414)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y_pos, nb_epoch=1, batch_size=250, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027155123881361629"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y_pos, batch_size=5, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negate feature space accuracy\n",
      "0.029367436858\n",
      "Stemming feature space accuracy\n",
      "0.0293251065135\n",
      "Stemming & negation feature space accuracy\n",
      "0.0287662911669\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/lawrencemacbook/Downloads/training_csv/neg_training_vects_x.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_negate = list(reader)\n",
    "X_negate = np.array(X_negate)\n",
    "#n_feature = len(X_negate[0])\n",
    "\n",
    "model_negate = Sequential()\n",
    "model_negate.add(Dense(2000, input_dim=len(X_negate[0]), init='uniform', activation='relu'))\n",
    "model_negate.add(Dropout(0.5))\n",
    "model_negate.add(Dense(500, activation='relu'))\n",
    "model_negate.add(Dropout(0.5))\n",
    "model_negate.add(Dense(1, activation='sigmoid'))\n",
    "model_negate.compile(loss='mse', optimizer='rmsprop')\n",
    "model_negate.fit(X_negate, y_pos, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print \"Negate feature space accuracy\"\n",
    "print model_negate.evaluate(X_negate, y_pos, batch_size=5, verbose = 0)\n",
    "\n",
    "with open('/Users/lawrencemacbook/Downloads/training_csv/stem_training_vects_x.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_stem = list(reader)\n",
    "X_stem = np.array(X_stem)\n",
    "#n_feature = len(X_stem[0])\n",
    "\n",
    "model_stem = Sequential()\n",
    "model_stem.add(Dense(2000, input_dim=len(X_stem[0]), init='uniform', activation='relu'))\n",
    "model_stem.add(Dropout(0.5))\n",
    "model_stem.add(Dense(500, activation='relu'))\n",
    "model_stem.add(Dropout(0.5))\n",
    "model_stem.add(Dense(1, activation='sigmoid'))\n",
    "model_stem.compile(loss='mse', optimizer='rmsprop')\n",
    "model_stem.fit(X_stem, y_pos, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print \"Stemming feature space accuracy\"\n",
    "print model_stem.evaluate(X_stem, y_pos, batch_size=5, verbose = 0)\n",
    "\n",
    "with open('/Users/lawrencemacbook/Downloads/training_csv/stem_neg_training_vects_x.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_stem_neg = list(reader)\n",
    "X_stem_neg = np.array(X_stem_neg)\n",
    "#n_feature = len(X_stem[0])\n",
    "\n",
    "model_stem_neg = Sequential()\n",
    "model_stem_neg.add(Dense(2000, input_dim=len(X_stem_neg[0]), init='uniform', activation='relu'))\n",
    "model_stem_neg.add(Dropout(0.5))\n",
    "model_stem_neg.add(Dense(500, activation='relu'))\n",
    "model_stem_neg.add(Dropout(0.5))\n",
    "model_stem_neg.add(Dense(1, activation='sigmoid'))\n",
    "model_stem_neg.compile(loss='mse', optimizer='rmsprop')\n",
    "model_stem_neg.fit(X_stem_neg, y_pos, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print \"Stemming & negation feature space accuracy\"\n",
    "print model_stem_neg.evaluate(X_stem_neg, y_pos, batch_size=5, verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11414\n",
      "13239\n",
      "9425\n",
      "11071\n"
     ]
    }
   ],
   "source": [
    "print len(X[0])\n",
    "print len(X_negate[0])\n",
    "print len(X_stem[0])\n",
    "print len(X_stem_neg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_dim=n_feature, init='uniform', activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(200, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128087e90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y_pos, nb_epoch=4, batch_size=250, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13871/13871 [==============================] - 37s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038688375336588428"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X, y_pos, batch_size=5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-20 17:16:39.922955\n",
      "Accuracy for 500-500\n",
      "13871/13871 [==============================] - 39s    \n",
      "0.0310015690128\n",
      "2016-04-20 17:34:22.576022\n"
     ]
    }
   ],
   "source": [
    "print datetime.datetime.now()\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(500, input_dim=n_feature, init='uniform', activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(500, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='mse', optimizer='rmsprop')\n",
    "model3.fit(X, y_pos, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print \"Accuracy for 500-500\"\n",
    "print model3.evaluate(X, y_pos, batch_size=5, verbose = 1)\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-20 17:47:58.767872\n",
      "0.0447634785921\n",
      "2016-04-20 18:19:01.286568\n",
      "0.0439471364734\n",
      "2016-04-20 18:49:49.333598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print datetime.datetime.now()\n",
    "model_neg = Sequential()\n",
    "model_neg.add(Dense(2000, input_dim=n_feature, init='uniform', activation='relu'))\n",
    "model_neg.add(Dropout(0.5))\n",
    "model_neg.add(Dense(500, activation='relu'))\n",
    "model_neg.add(Dropout(0.5))\n",
    "model_neg.add(Dense(1, activation='sigmoid'))\n",
    "model_neg.compile(loss='mse', optimizer='rmsprop')\n",
    "model_neg.fit(X, y_neg, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print model_neg.evaluate(X, y_neg, batch_size=5, verbose = 0)\n",
    "print datetime.datetime.now()\n",
    "model_neu = Sequential()\n",
    "model_neu.add(Dense(2000, input_dim=n_feature, init='uniform', activation='relu'))\n",
    "model_neu.add(Dropout(0.5))\n",
    "model_neu.add(Dense(500, activation='relu'))\n",
    "model_neu.add(Dropout(0.5))\n",
    "model_neu.add(Dense(1, activation='sigmoid'))\n",
    "model_neu.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "model_neu.fit(X, y_neu, nb_epoch=25, batch_size=250, verbose=0)\n",
    "print model_neu.evaluate(X, y_neu, batch_size=5, verbose = 0)\n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0436366160389\n"
     ]
    }
   ],
   "source": [
    "model_neg.fit(X, y_neg, nb_epoch=5, batch_size=250, verbose=0)\n",
    "print model_neg.evaluate(X, y_neg, batch_size=5, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models_new/model_mlp_pos.json', 'w').write(json_string)\n",
    "model.save_weights('models_new/model_mlp_pos_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model_neg.to_json()\n",
    "open('models_new/model_mlp_neg.json', 'w').write(json_string)\n",
    "model_neg.save_weights('models_new/model_mlp_neg_weights.h5')\n",
    "\n",
    "json_string = model_neu.to_json()\n",
    "open('models_new/model_mlp_neu.json', 'w').write(json_string)\n",
    "model_neu.save_weights('models_new/model_mlp_neu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/lawrencemacbook/Downloads/validation/don_trump/Correction/raw_validation_vects_correction.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_val_trump = list(reader)\n",
    "    X_val_trump = np.array(X_val_trump)\n",
    "with open('/Users/lawrencemacbook/Downloads/validation/jeb_bush/Correction/raw_validation_vects_correction.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_val_bush = list(reader)\n",
    "    X_val_bush = np.array(X_val_bush)\n",
    "with open('/Users/lawrencemacbook/Downloads/validation/ted_cruz/Correction/raw_validation_vects_correction.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    X_val_cruz = list(reader)\n",
    "    X_val_cruz = np.array(X_val_cruz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06951041] [ 0.75956383] [ 0.17092576]\n"
     ]
    }
   ],
   "source": [
    "proba_pos_trump = model.predict_proba(X_val_trump, batch_size=32, verbose=0)\n",
    "proba_neg_trump = model_neg.predict_proba(X_val_trump, batch_size=32, verbose=0)\n",
    "proba_neu_trump = model_neu.predict_proba(X_val_trump, batch_size=32, verbose=0)\n",
    "\n",
    "normalized_pos_trump = []\n",
    "normalized_neg_trump = []\n",
    "normalized_neu_trump = []\n",
    "for i in range(len(X_val_trump)):\n",
    "    z = proba_pos_trump[i] + proba_neg_trump[i] + proba_neu_trump[i]\n",
    "    normalized_pos_trump.append(proba_pos_trump[i]/z)\n",
    "    normalized_neg_trump.append(proba_neg_trump[i]/z)\n",
    "    normalized_neu_trump.append(proba_neu_trump[i]/z)\n",
    "\n",
    "proba_pos_trump_sum = sum(normalized_pos_trump)\n",
    "proba_neg_trump_sum = sum(normalized_neg_trump)\n",
    "proba_neu_trump_sum = sum(normalized_neu_trump) \n",
    "\n",
    "z_score_trump = sum([proba_pos_trump_sum, proba_neg_trump_sum, proba_neu_trump_sum])\n",
    "print proba_pos_trump_sum/z_score_trump, proba_neg_trump_sum/z_score_trump, proba_neu_trump_sum/z_score_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.053117] [ 0.74478654] [ 0.20209646]\n"
     ]
    }
   ],
   "source": [
    "proba_pos_bush = model.predict_proba(X_val_bush, batch_size=32, verbose=0)\n",
    "proba_neg_bush = model_neg.predict_proba(X_val_bush, batch_size=32, verbose=0)\n",
    "proba_neu_bush = model_neu.predict_proba(X_val_bush, batch_size=32, verbose=0)\n",
    "\n",
    "normalized_pos_bush = []\n",
    "normalized_neg_bush = []\n",
    "normalized_neu_bush = []\n",
    "for i in range(len(X_val_bush)):\n",
    "    z = proba_pos_bush[i] + proba_neg_bush[i] + proba_neu_bush[i]\n",
    "    normalized_pos_bush.append(proba_pos_bush[i]/z)\n",
    "    normalized_neg_bush.append(proba_neg_bush[i]/z)\n",
    "    normalized_neu_bush.append(proba_neu_bush[i]/z)\n",
    "\n",
    "proba_pos_bush_sum = sum(normalized_pos_bush)\n",
    "proba_neg_bush_sum = sum(normalized_neg_bush)\n",
    "proba_neu_bush_sum = sum(normalized_neu_bush) \n",
    "\n",
    "z_score_bush = sum([proba_pos_bush_sum, proba_neg_bush_sum, proba_neu_bush_sum])\n",
    "print proba_pos_bush_sum/z_score_bush, proba_neg_bush_sum/z_score_bush, proba_neu_bush_sum/z_score_bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19894325] [ 0.50576261] [ 0.29529414]\n"
     ]
    }
   ],
   "source": [
    "proba_pos_cruz = model.predict_proba(X_val_cruz, batch_size=32, verbose=0)\n",
    "proba_neg_cruz = model_neg.predict_proba(X_val_cruz, batch_size=32, verbose=0)\n",
    "proba_neu_cruz = model_neu.predict_proba(X_val_cruz, batch_size=32, verbose=0)\n",
    "\n",
    "normalized_pos_cruz = []\n",
    "normalized_neg_cruz = []\n",
    "normalized_neu_cruz = []\n",
    "for i in range(len(X_val_cruz)):\n",
    "    z = proba_pos_cruz[i] + proba_neg_cruz[i] + proba_neu_cruz[i]\n",
    "    normalized_pos_cruz.append(proba_pos_cruz[i]/z)\n",
    "    normalized_neg_cruz.append(proba_neg_cruz[i]/z)\n",
    "    normalized_neu_cruz.append(proba_neu_cruz[i]/z)\n",
    "\n",
    "proba_pos_cruz_sum = sum(normalized_pos_cruz)\n",
    "proba_neg_cruz_sum = sum(normalized_neg_cruz)\n",
    "proba_neu_cruz_sum = sum(normalized_neu_cruz) \n",
    "\n",
    "z_score_cruz = sum([proba_pos_cruz_sum, proba_neg_cruz_sum, proba_neu_cruz_sum])\n",
    "print proba_pos_cruz_sum/z_score_cruz, proba_neg_cruz_sum/z_score_cruz, proba_neu_cruz_sum/z_score_cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06930168] [ 0.77326376] [ 0.15743457]\n",
      "[ 0.05162042] [ 0.76949084] [ 0.17888873]\n",
      "[ 0.19730234] [ 0.53029881] [ 0.27239886]\n"
     ]
    }
   ],
   "source": [
    "z_trump = sum(proba_pos_trump) + sum(proba_neg_trump) + sum(proba_neu_trump)\n",
    "print sum(proba_pos_trump)/z_trump, sum(proba_neg_trump)/z_trump, sum(proba_neu_trump)/z_trump\n",
    "\n",
    "z_bush = sum(proba_pos_bush) + sum(proba_neg_bush) + sum(proba_neu_bush)\n",
    "print sum(proba_pos_bush)/z_bush, sum(proba_neg_bush)/z_bush, sum(proba_neu_bush)/z_bush\n",
    "\n",
    "z_cruz = sum(proba_pos_cruz) + sum(proba_neg_cruz) + sum(proba_neu_cruz)\n",
    "print sum(proba_pos_cruz)/z_cruz, sum(proba_neg_cruz)/z_cruz, sum(proba_neu_cruz)/z_cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_trump = sum(proba_pos_trump) + sum(proba_neg_trump) + sum(proba_neu_trump)\n",
    "print sum(proba_pos_trump)/z_trump, sum(proba_neg_trump)/z_trump, sum(proba_neu_trump)/z_trump\n",
    "\n",
    "z_bush = sum(proba_pos_bush) + sum(proba_neg_bush) + sum(proba_neu_bush)\n",
    "print sum(proba_pos_bush)/z_bush, sum(proba_neg_bush)/z_bush, sum(proba_neu_bush)/z_bush\n",
    "\n",
    "z_cruz = sum(proba_pos_cruz) + sum(proba_neg_cruz) + sum(proba_neu_cruz)\n",
    "print sum(proba_pos_cruz)/z_cruz, sum(proba_neg_cruz)/z_cruz, sum(proba_neu_cruz)/z_cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 3\n",
    "\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.25       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos_bar = (0.06930168, 0.05162042, 0.19730234)\n",
    "neg_bar = (0.77326376, 0.76949084, 0.53029881) \n",
    "neu_bar = (0.15743457, 0.17888873, 0.27239886)\n",
    "\n",
    "rects1 = ax.bar(ind+0.2, pos_bar, width, color='b' )\n",
    "rects2 = ax.bar(ind+.2 + width, neg_bar, width, color='r')\n",
    "rects3 = ax.bar(ind+.2 + width*2, neu_bar, width, color='y')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Twitter Sentiment Score')\n",
    "ax.set_title('GOP Candidate Twitter Reception, Aug 7~9, 2015')\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(('Donanld Trump', 'Jeb Bush', 'Ted Cruz'))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Positive', 'Negative', 'Neutral'))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                height,\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_ylim([0.0,1.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump20160412Vects.csv',\n",
       " 'trump20160413Vects.csv',\n",
       " 'trump20160414Vects.csv',\n",
       " 'trump20160415Vects.csv',\n",
       " 'trump20160416Vects.csv',\n",
       " 'trump20160417Vects.csv',\n",
       " 'trump20160418Vects.csv']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/lawrencemacbook/Downloads/test_data/don_trump/\"\n",
    "file_list = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trump_test_list = []\n",
    "for file_name in file_list:\n",
    "    with open(mypath+file_name, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        X_trump_test = list(reader)\n",
    "        X_trump_test = np.array(X_trump_test)\n",
    "    X_trump_test_list.append(X_trump_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11301223] [ 0.73828947] [ 0.1486983]\n",
      "[ 0.08425121] [ 0.72921353] [ 0.18653527]\n",
      "[ 0.10497941] [ 0.7308138] [ 0.16420679]\n",
      "[ 0.13925969] [ 0.70794636] [ 0.15279395]\n",
      "[ 0.12048822] [ 0.73020667] [ 0.14930511]\n",
      "[ 0.13499086] [ 0.70416208] [ 0.16084706]\n",
      "[ 0.10705858] [ 0.73716557] [ 0.15577586]\n"
     ]
    }
   ],
   "source": [
    "trump_test_scores = []\n",
    "for X_test in X_trump_test_list:\n",
    "    proba_pos_trump = model.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "    proba_neg_trump = model_neg.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "    proba_neu_trump = model_neu.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "\n",
    "    normalized_pos_trump = []\n",
    "    normalized_neg_trump = []\n",
    "    normalized_neu_trump = []\n",
    "    for i in range(len(X_test)):\n",
    "        z = proba_pos_trump[i] + proba_neg_trump[i] + proba_neu_trump[i]\n",
    "        normalized_pos_trump.append(proba_pos_trump[i]/z)\n",
    "        normalized_neg_trump.append(proba_neg_trump[i]/z)\n",
    "        normalized_neu_trump.append(proba_neu_trump[i]/z)\n",
    "\n",
    "    proba_pos_trump_sum = sum(normalized_pos_trump)\n",
    "    proba_neg_trump_sum = sum(normalized_neg_trump)\n",
    "    proba_neu_trump_sum = sum(normalized_neu_trump) \n",
    "\n",
    "    z_score_trump = sum([proba_pos_trump_sum, proba_neg_trump_sum, proba_neu_trump_sum])\n",
    "    print proba_pos_trump_sum/z_score_trump, proba_neg_trump_sum/z_score_trump, proba_neu_trump_sum/z_score_trump\n",
    "    trump_test_scores.append([proba_pos_trump_sum/z_score_trump, proba_neg_trump_sum/z_score_trump, proba_neu_trump_sum/z_score_trump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_test_scores_col = zip(*trump_test_scores)\n",
    "trump_test_scores_col_list = []\n",
    "for x in trump_test_scores_col:\n",
    "    temp = []\n",
    "    for y in x:\n",
    "        temp.append(y[0])\n",
    "    trump_test_scores_col_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 7\n",
    "\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.25       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos_bar = (0.06930168, 0.05162042, 0.19730234)\n",
    "neg_bar = (0.77326376, 0.76949084, 0.53029881) \n",
    "neu_bar = (0.15743457, 0.17888873, 0.27239886)\n",
    "\n",
    "rects1 = ax.bar(ind+0.2, trump_test_scores_col_list[0], width, color='b' )\n",
    "rects2 = ax.bar(ind+.2 + width, trump_test_scores_col_list[1], width, color='r')\n",
    "rects3 = ax.bar(ind+.2 + width*2, trump_test_scores_col_list[2], width, color='y')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Twitter Sentiment Score')\n",
    "ax.set_title('GOP Candidate Twitter Reception, Aug 7~9, 2015')\n",
    "ax.set_xticks(ind + width)\n",
    "# ax.set_xticklabels(('Donanld Trump', 'Jeb Bush', 'Ted Cruz'))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Positive', 'Negative', 'Neutral'))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                height,\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "#autolabel(rects1)\n",
    "#autolabel(rects2)\n",
    "#autolabel(rects3)\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_ylim([0.0,1.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "line1, = plt.plot(range(N), trump_test_scores_col_list[0],'bo-', label='Positive')\n",
    "line2, = plt.plot(range(N), trump_test_scores_col_list[1],'ro-', label='Negative')\n",
    "line3, = plt.plot(range(N), trump_test_scores_col_list[2],'yo-', label='Neutral')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "plt.legend(handles=[line1, line2, line3])\n",
    "ax.set_ylabel('Twitter Sentiment Score')\n",
    "ax.set_title('Sentiment Trend Donald Trump 04/12/2016~04/18/2016')\n",
    "ax.set_xticklabels(('04/12','04/13','04/14','04/15','04/16','04/17','04/18'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16831588] [ 0.64186259] [ 0.18982153]\n",
      "[ 0.16168068] [ 0.70720892] [ 0.1311104]\n",
      "[ 0.2010925] [ 0.59157809] [ 0.20732942]\n",
      "[ 0.25944445] [ 0.53623929] [ 0.20431626]\n",
      "[ 0.27158185] [ 0.53078013] [ 0.19763802]\n",
      "[ 0.2175587] [ 0.59427873] [ 0.18816256]\n",
      "[ 0.21287443] [ 0.60672598] [ 0.18039959]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "mypath = \"/Users/lawrencemacbook/Downloads/test_data/ted_cruz/\"\n",
    "file_list = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Convert data into np arrays\n",
    "X_trump_test_list = []\n",
    "for file_name in file_list:\n",
    "    with open(mypath+file_name, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        X_trump_test = list(reader)\n",
    "        X_trump_test = np.array(X_trump_test)\n",
    "    X_trump_test_list.append(X_trump_test)\n",
    "    \n",
    "# Calculate raw scores\n",
    "trump_test_scores = []\n",
    "for X_test in X_trump_test_list:\n",
    "    proba_pos_trump = model.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "    proba_neg_trump = model_neg.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "    proba_neu_trump = model_neu.predict_proba(X_test, batch_size=32, verbose=0)\n",
    "\n",
    "    normalized_pos_trump = []\n",
    "    normalized_neg_trump = []\n",
    "    normalized_neu_trump = []\n",
    "    for i in range(len(X_test)):\n",
    "        z = proba_pos_trump[i] + proba_neg_trump[i] + proba_neu_trump[i]\n",
    "        normalized_pos_trump.append(proba_pos_trump[i]/z)\n",
    "        normalized_neg_trump.append(proba_neg_trump[i]/z)\n",
    "        normalized_neu_trump.append(proba_neu_trump[i]/z)\n",
    "\n",
    "    proba_pos_trump_sum = sum(normalized_pos_trump)\n",
    "    proba_neg_trump_sum = sum(normalized_neg_trump)\n",
    "    proba_neu_trump_sum = sum(normalized_neu_trump) \n",
    "\n",
    "    z_score_trump = sum([proba_pos_trump_sum, proba_neg_trump_sum, proba_neu_trump_sum])\n",
    "    print proba_pos_trump_sum/z_score_trump, proba_neg_trump_sum/z_score_trump, proba_neu_trump_sum/z_score_trump\n",
    "    trump_test_scores.append([proba_pos_trump_sum/z_score_trump, proba_neg_trump_sum/z_score_trump, proba_neu_trump_sum/z_score_trump])\n",
    "\n",
    "# Extract score columns/sort by sentiment\n",
    "trump_test_scores_col = zip(*trump_test_scores)\n",
    "trump_test_scores_col_list = []\n",
    "for x in trump_test_scores_col:\n",
    "    temp = []\n",
    "    for y in x:\n",
    "        temp.append(y[0])\n",
    "    trump_test_scores_col_list.append(temp)\n",
    "    \n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "line1, = plt.plot(range(N), trump_test_scores_col_list[0],'bo-', label='Positive')\n",
    "line2, = plt.plot(range(N), trump_test_scores_col_list[1],'ro-', label='Negative')\n",
    "line3, = plt.plot(range(N), trump_test_scores_col_list[2],'yo-', label='Neutral')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "plt.legend(handles=[line1, line2, line3])\n",
    "ax.set_ylabel('Twitter Sentiment Score')\n",
    "ax.set_title('Sentiment Trend Ted Cruz 04/12/2016~04/18/2016')\n",
    "ax.set_xticklabels(('04/12','04/13','04/14','04/15','04/16','04/17','04/18'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
